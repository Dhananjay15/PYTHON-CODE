{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89be1518",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data_batch_1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 20>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m6\u001b[39m):\n\u001b[0;32m     21\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_batch_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i)\n\u001b[1;32m---> 22\u001b[0m     open_data \u001b[38;5;241m=\u001b[39m \u001b[43munpickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     24\u001b[0m         data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack((data, open_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36munpickle\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munpickle\u001b[39m(file):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fo:\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;28mdict\u001b[39m \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(fo, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data_batch_1'"
     ]
    }
   ],
   "source": [
    "# dataset link: https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "import pickle\n",
    "\n",
    "\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='latin1')\n",
    "    return dict\n",
    "\n",
    "def grayscale(im):\n",
    "    return im.reshape(im.shape[0], 3, 32, 32).mean(1).reshape(im.shape[0], -1)\n",
    "\n",
    "# Load the data into memory\n",
    "data, labels = [], []\n",
    "## Loop over the b\n",
    "for i in range(1, 6):\n",
    "    filename = 'data_batch_' + str(i)\n",
    "    open_data = unpickle(filename)\n",
    "    if len(data) > 0:\n",
    "        data = np.vstack((data, open_data['data']))\n",
    "        labels = np.hstack((labels, open_data['labels']))\n",
    "    else:\n",
    "        data = open_data['data']\n",
    "        labels = open_data['labels']\n",
    "\n",
    "data = grayscale(data)\n",
    "x = np.matrix(data)\n",
    "y = np.array(labels)\n",
    "print(x.shape)\n",
    "(50000, 1024)\n",
    "\n",
    "horse_i = np.where(y == 7)[0]\n",
    "horse_x = x[horse_i]\n",
    "print(np.shape(horse_x)) \n",
    "(5000, 1024)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_image(image, shape=[32, 32], cmap = \"Greys_r\"):\n",
    "    plt.imshow(image.reshape(shape), cmap=cmap,interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")   \n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(x).repeat().batch(1)\n",
    "#iter = dataset.make_initializable_iterator() # create the iteratorfeatures = iter.get_next()\n",
    "\n",
    "\n",
    "## Parameters\n",
    "n_inputs = 32 * 32\n",
    "BATCH_SIZE = 1\n",
    "batch_size = tf.placeholder(tf.int64)\n",
    "\n",
    "# using a placeholder\n",
    "tf.disable_v2_behavior()\n",
    "x = tf.placeholder(tf.float32, shape=[None,n_inputs])\n",
    "## Dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices(x).repeat().batch(batch_size)\n",
    "iter = dataset.make_initializable_iterator() # create the iterator\n",
    "features = iter.get_next()\n",
    "\n",
    "## Print the image\n",
    "with tf.Session() as sess:\n",
    "    # feed the placeholder with data\n",
    "    sess.run(iter.initializer, feed_dict={x: horse_x,\n",
    "                                         batch_size: BATCH_SIZE}) \n",
    "    print(sess.run(features).shape) \n",
    "    plot_image(sess.run(features), shape=[32, 32], cmap = \"Greys_r\")\n",
    "(1, 1024)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
